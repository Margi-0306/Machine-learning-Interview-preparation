# Machine-learning-Interview-preparation

# Which functions in SQL do you like the most?
# Explain OLAP cubes and a use case explaining business analytics application.
# What are data normalization and non-normalization?
# What happens to the data of a table with foreign keys when the associated table with primary keys has been updated?
# What do you understand by cascading referential integrity?
# Explain the difference between the linear and logistic regression and use examples.
# What is an independent variable, and what if I have three independent variables in my model and no dependent variable?
# Write an equation for the multivariance or multiple regression model.
# Given a sample with n observations, how could you test a hypothesis?
# What are the Assumptions of ANOVA.
# What test would you use for a small sample?
# What is the null hypothesis?
# What are type 1 and type 2 errors?
# Use the following tables to write a query to retrieve data for customers who registered in the past ten days and spent over $100. Write another query to retrieve data for customers that spent over $100 in the past seven days. The first table is a customer purchase table with five columns: customer id, purchase date, product id, unit price, and units purchased. The second table is a customer details table with two columns: customer id and registration date.
# What is the probability of generating ten consecutive numbers in ascending order out of 100 numbers?
# How would you merge two tables in SQL?
# Write a function to calculate the Fibonacci code in any of these languages (VBA, Python, Java).
# What is the difference between DELETE TABLE and TRUNCATE TABLE in SQL?
# Whatâ€™s the difference between an INNER and OUTER JOIN?

## Scenario based interview question

# Data Pipeline Creation: Describe how you would design and implement a data pipeline to ETL data from different sources ( SQL, API, files etc) into a data warehouse.
# Data Cleaning Strategies: How would you handle and clean a dataset that has missing values, duplicates and inconsistent data formats to prepare it for analysis?
# Handling Large Datasets: If you are working with large datasets that are causing performance issues, what strategies would you use to optimize data processing?
# Database Schema Design: Explain how you would design a normalized database schema for an e-commerce application.
# SQL Performance Tuning: What steps would you take to optimize a slow-running SQL query?
# Data Warehousing Concepts: Explain the differences between a star schema and a snowflake schema in data warehousing.
# ETL Tools: Describe your experience with ETL tools such as Apache NiFi, Talend or Microsoft SSIS. How did you use them in a project?
# Scheduling and Automation: How would you set up and manage scheduled data jobs to ensure data is loaded into the data warehouse regularly?
# Data Versioning: How would you implement data versioning in a data warehouse to keep track of changes over time?
# Data Security: Describe the steps you would take to secure sensitive data in a database and during data transmission.
# Big Data Technologies: Explain your experience with big data technologies such as Hadoop, Spark or Kafka. How did you use them in a project?
# Cloud Data Services: Describe how you have used cloud data warehousing services (AWS Redshift, Google BigQuery, Azure Synapse , Snowflake ) in your projects.
# Data Integration: How would you integrate data from disparate sources ( SQL databases, APIs, third-party services etc) into a unified data warehouse?
# Data Lake vs. Data Warehouse: Explain the differences between a data lake and a data warehouse. When would you use one over the other?
# Error Handling in Data Pipelines: How do you manage and resolve errors in your data pipelines to ensure data integrity?
# Data Governance: What practices would you implement to ensure data quality, consistency, and governance in your data engineering processes?
# Scripting and Automation: Describe how you have used scripting languages (Python, Bash) to automate data processing tasks.
# Collaborative Projects: Discuss a project where you collaborated with data analysts or data scientists. How did you ensure smooth communication and integration of your work?
# Data Migration: Describe a scenario where you had to migrate data from one system to another. What challenges did you face and how did you overcome them?
